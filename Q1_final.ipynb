{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Q1 - final.ipynb",
      "version": "0.3.2",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "[View in Colaboratory](https://colab.research.google.com/github/orico/UnitTestAndDecoratorLogger/blob/master/Q1_final.ipynb)"
      ]
    },
    {
      "metadata": {
        "id": "BDzAPs7MuxzR",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "!apt-get install -y -qq software-properties-common python-software-properties module-init-tools\n",
        "!add-apt-repository -y ppa:alessandro-strada/ppa 2>&1 > /dev/null\n",
        "!apt-get update -qq 2>&1 > /dev/null\n",
        "!apt-get -y install -qq google-drive-ocamlfuse fuse\n",
        "\n",
        "from google.colab import auth\n",
        "auth.authenticate_user()\n",
        "\n",
        "from oauth2client.client import GoogleCredentials\n",
        "creds = GoogleCredentials.get_application_default()\n",
        "\n",
        "import getpass\n",
        "!google-drive-ocamlfuse -headless -id={creds.client_id} -secret={creds.client_secret} < /dev/null 2>&1 | grep URL\n",
        "vcode = getpass.getpass()\n",
        "!echo {vcode} | google-drive-ocamlfuse -headless -id={creds.client_id} -secret={creds.client_secret}\n",
        "!mkdir -p drive\n",
        "!google-drive-ocamlfuse drive\n",
        "\n",
        "import os\n",
        "os.chdir(\"drive/Colab Notebooks/Interviewhomeworktask 2018/\")\n",
        "!ls\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "rrKvcD9NtOVo",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        },
        "outputId": "e94bd040-4124-4ee4-9539-80f75405184f"
      },
      "cell_type": "code",
      "source": [
        "#!/usr/bin/python\n",
        "# -*- coding: utf-8 -*-\n",
        "import os\n",
        "import re\n",
        "import nltk\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.metrics import confusion_matrix\n",
        "from sklearn.naive_bayes import GaussianNB\n",
        "from sklearn import metrics\n",
        "from sklearn import tree\n",
        "from sklearn.model_selection import train_test_split, ShuffleSplit, KFold, cross_val_score\n",
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "from sklearn.ensemble import RandomForestClassifier  \n",
        "\n",
        "\n",
        "%matplotlib inline\n",
        "\n",
        "# !pip install gensim\n",
        "# import gensim\n",
        "# !pip install graphviz\n",
        "# import graphviz\n",
        "!ls\n"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "interviewClassificationTask.csv  Q2.ipynb\t\t\t   tree.dot\r\n",
            "Q1.ipynb\t\t\t Source.gv\t\t\t   unigrams\r\n",
            "Q2 - Final.ipynb\t\t StuccomediaInterviewHomework.pdf\r\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "P-j8pK0Jtn2j",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "The first question is a pure data science task and we would like to see a python notebook with the steps.\n",
        "\n",
        "Question 1:\n",
        "\n",
        "Attached are short text and their classification to either 0\\1. Write a classifier in python that\n",
        "\n",
        "predicts the class (python notebook that describes the steps towards solution)\n",
        "The file attached."
      ]
    },
    {
      "metadata": {
        "id": "ruT-Ii9ltc2I",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        },
        "outputId": "36dbed1f-6946-494d-8b55-aa59f79c1015"
      },
      "cell_type": "code",
      "source": [
        "df = pd.read_csv('interviewClassificationTask.csv',encoding = \"ISO-8859-1\")\n",
        "df = df.drop(df.columns[[2, 3, 4]], axis=1)\n",
        "\n",
        "print('unbalanced classes:')\n",
        "print('class 0:', (float(df.shape[0]) - float(np.sum(df['v1']))) / float(df.shape[0]) * 100) \n",
        "print('class 1:', float(np.sum(df['v1'])) / float(df.shape[0]) * 100)"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "unbalanced classes:\n",
            "class 0: 86.59368269921033\n",
            "class 1: 13.406317300789663\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "25htMINqd-sH",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 153
        },
        "outputId": "2b38b6bb-e767-4c56-ef58-b26b14ebeb4c"
      },
      "cell_type": "code",
      "source": [
        "nltk.download('stopwords')\n",
        "wpt = nltk.WordPunctTokenizer()\n",
        "stop_words = nltk.corpus.stopwords.words('english')\n",
        "\n",
        "def normalize_document(doc):\n",
        "    # lower case and remove special characters\\whitespaces\n",
        "    doc = re.sub(r'[^a-zA-Z\\s]', '', doc, re.I|re.A)\n",
        "    doc = doc.lower()\n",
        "    doc = doc.strip()\n",
        "    # tokenize document\n",
        "    tokens = wpt.tokenize(doc)\n",
        "    # filter stopwords out of document\n",
        "    filtered_tokens = [token for token in tokens if token not in stop_words]\n",
        "    # re-create document from filtered tokens\n",
        "    doc = ' '.join(filtered_tokens)\n",
        "    return doc\n",
        "\n",
        "normalize_corpus = np.vectorize(normalize_document)\n",
        "corpus = df['v2'].values\n",
        "norm_corpus = normalize_corpus(corpus)\n",
        "print(norm_corpus)"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package stopwords to /content/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n",
            "['go jurong point crazy available bugis n great world la e buffet cine got amore wat'\n",
            " 'ok lar joking wif u oni'\n",
            " 'free entry wkly comp win fa cup final tkts st may text fa receive entry questionstd txt ratetcs apply overs'\n",
            " ... 'pity mood soany suggestions'\n",
            " 'guy bitching acted like id interested buying something else next week gave us free'\n",
            " 'rofl true name']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "cNxgen-GUoxK",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 153
        },
        "outputId": "9ab43d0f-89b8-4050-fb48-e06d1fa595c2"
      },
      "cell_type": "code",
      "source": [
        "cv = CountVectorizer(min_df=0., max_df=1.)\n",
        "cv_matrix = cv.fit_transform(norm_corpus)\n",
        "cv_matrix = cv_matrix.toarray()\n",
        "print(cv_matrix)\n",
        "print(cv_matrix.shape)\n",
        "\n",
        "# # get all unique words in the corpus\n",
        "# vocab = cv.get_feature_names()\n",
        "# # show document feature vectors\n",
        "# p = pd.DataFrame(cv_matrix, columns=vocab)\n",
        "# print(p.shape)\n",
        "# print(p.head())\n"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[0 0 0 ... 0 0 0]\n",
            " [0 0 0 ... 0 0 0]\n",
            " [0 0 0 ... 0 0 0]\n",
            " ...\n",
            " [0 0 0 ... 0 0 0]\n",
            " [0 0 0 ... 0 0 0]\n",
            " [0 0 0 ... 0 0 0]]\n",
            "(5572, 8389)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "vxyN--HkU3iB",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "collapsed": true,
        "outputId": "ecefe733-6b70-4322-cd4d-6526cfb62b28"
      },
      "cell_type": "code",
      "source": [
        "# you can set the n-gram range to 1,2 to get unigrams as well as bigrams\n",
        "bv = CountVectorizer(ngram_range=(2,2))\n",
        "bv_matrix = bv.fit_transform(norm_corpus)\n",
        "print(bv_matrix.shape)\n",
        "bv_matrix = bv_matrix.toarray()\n",
        "print(bv_matrix.shape)\n",
        "\n",
        "# vocab = bv.get_feature_names()\n",
        "# pd.DataFrame(bv_matrix, columns=vocab)"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(5572, 30433)\n",
            "(5572, 30433)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "3vOj6kZOVBzf",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "collapsed": true,
        "outputId": "e1fc43a3-dd46-4712-99ad-af43b6e975e1"
      },
      "cell_type": "code",
      "source": [
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "\n",
        "tv = TfidfVectorizer(min_df=0., max_df=1., use_idf=True)\n",
        "tv_matrix = tv.fit_transform(norm_corpus)\n",
        "print(tv_matrix.shape)\n",
        "tv_matrix = tv_matrix.toarray()\n",
        "print(tv_matrix.shape)\n",
        "# vocab = tv.get_feature_names()\n",
        "# pd.DataFrame(np.round(tv_matrix, 2), columns=vocab)"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(5572, 8389)\n",
            "(5572, 8389)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "FoN8MDCfXR_0",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 612
        },
        "outputId": "3ea051c3-c66b-4122-fc66-af6a1fd8bc66"
      },
      "cell_type": "code",
      "source": [
        "def train_test(matrix):\n",
        "  X = matrix\n",
        "  y = df['v1']\n",
        "\n",
        "  X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, random_state=42)\n",
        "  print(X_train.shape)\n",
        "  print(X_test.shape)\n",
        "\n",
        "  print('\\nlabel ratio in train-set:')\n",
        "  print('class 0:', (float(X_train.shape[0]) - float(np.sum(y_train))) / float(X_train.shape[0]) * 100) \n",
        "  print('class 1:', float(np.sum(y_train)) / float(X_train.shape[0]) * 100)\n",
        "  print()\n",
        "  \n",
        "  print('\\nlabel ratio in test-set:')\n",
        "  print('class 0:', (float(X_test.shape[0]) - float(np.sum(y_test))) / float(X_test.shape[0]) * 100) \n",
        "  print('class 1:', float(np.sum(y_test)) / float(X_test.shape[0]) * 100)\n",
        "  print()\n",
        "  \n",
        "  clf = tree.DecisionTreeClassifier()\n",
        "  clf.fit(X, y)\n",
        "  prediction = clf.predict(X_test)\n",
        "  print('Decision Tree:')\n",
        "  print('\\n', confusion_matrix(y_test, prediction))\n",
        "  print('\\n', 'Train/Test Accuracy: %', clf.score(X_test, y_test) * 100 )  \n",
        "  tree.export_graphviz(clf, out_file='tree.dot')  \n",
        "  print()\n",
        "  \n",
        "  \n",
        "  clf2 = RandomForestClassifier(max_depth=50, random_state=0)\n",
        "  clf2.fit(X, y)\n",
        "  prediction = clf2.predict(X_test)\n",
        "  print('Random Forest:')\n",
        "  print('\\n', confusion_matrix(y_test, prediction))\n",
        "  print('\\n', 'Train/Test Accuracy: %', clf2.score(X_test, y_test) * 100 )  \n",
        "  print()\n",
        "  \n",
        "  clf3 = GaussianNB()\n",
        "  clf3.fit(X, y)\n",
        "  prediction = clf3.predict(X_test)\n",
        "  print('GaussianNB:')\n",
        "  print('\\n', confusion_matrix(y_test, prediction))\n",
        "  print('\\n', 'Train/Test Accuracy: %', clf3.score(X_test, y_test) * 100 )  \n",
        "  print()\n",
        "  return clf\n",
        "\n",
        "\n",
        "def KFold_split(matrix):  \n",
        "  X = matrix\n",
        "  y = df['v1']\n",
        "  \n",
        "  cv = KFold(n_splits = 3, shuffle = True)\n",
        "  clf = tree.DecisionTreeClassifier()\n",
        "  scores = cross_val_score(clf, X, y, cv=cv)\n",
        "  print('Decision Tree CV scores:', scores, '\\nmean:', np.mean(scores))\n",
        "\n",
        "clf = train_test(cv_matrix)\n",
        "KFold_split(cv_matrix)   \n",
        "\n",
        "# # train_test(bv_matrix) \n",
        "# # KFold_split(bv_matrix)  \n",
        "\n",
        "# KFold_split(tv_matrix)  \n",
        "# train_test(tv_matrix) \n",
        "\n",
        "# uni_bi = np.hstack((cv_matrix,bv_matrix))\n",
        "# train_test(uni_bi) \n",
        "# KFold_split(uni_bi) \n",
        "\n",
        "# unibitf = np.hstack((uni_bi,tv_matrix))\n",
        "# uni_bi = ''  \n",
        "# cv_matrix = ''  \n",
        "# bv_matrix = ''  \n",
        "# tv_matrix = ''  \n",
        "# train_test(unibitf)\n",
        "# KFold_split(unibitf) "
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(4179, 8389)\n",
            "(1393, 8389)\n",
            "\n",
            "label ratio in train-set:\n",
            "class 0: 86.69538167025604\n",
            "class 1: 13.304618329743958\n",
            "\n",
            "\n",
            "label ratio in test-set:\n",
            "class 0: 86.28858578607323\n",
            "class 1: 13.711414213926776\n",
            "\n",
            "Decision Tree:\n",
            "\n",
            " [[1202    0]\n",
            " [   0  191]]\n",
            "\n",
            " Train/Test Accuracy: % 100.0\n",
            "\n",
            "Random Forest:\n",
            "\n",
            " [[1202    0]\n",
            " [  27  164]]\n",
            "\n",
            " Train/Test Accuracy: % 98.06173725771716\n",
            "\n",
            "GaussianNB:\n",
            "\n",
            " [[1107   95]\n",
            " [   0  191]]\n",
            "\n",
            " Train/Test Accuracy: % 93.18018664752333\n",
            "\n",
            "Decision Tree CV scores: [0.96770721 0.9628433  0.95799677] \n",
            "mean: 0.9628490922254432\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}