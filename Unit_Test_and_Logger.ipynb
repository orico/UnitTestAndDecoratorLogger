{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Unit Test and Logger.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "[View in Colaboratory](https://colab.research.google.com/github/orico/UnitTestAndDecoratorLogger/blob/master/Unit_Test_and_Logger.ipynb)"
      ]
    },
    {
      "metadata": {
        "id": "_MIkFiB0R7i-",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "There are many definitions to what the scope of a data-scientist job is. On one hand, the norm in many companies is to concentrate only on model creation, which is understandable because your time is expensive and should be used mainly for your field of expertese. However, in other companies, an end-to-end definition is \n",
        "\n",
        "The following is an small example of unit testing and logging for a 10-class supervised problem using the MNIST dataset. The python code for unit testing and logger were made by Corey Schafer and are available [here](https://github.com/CoreyMSchafer/code_snippets/tree/master/Python-Unit-Testing) and [here](https://github.com/CoreyMSchafer/code_snippets/tree/master/Decorators). \n",
        "\n",
        "\n",
        "Additional asserts are vailable [here](https://docs.python.org/3/library/unittest.html#unittest.TestCase.debug)"
      ]
    },
    {
      "metadata": {
        "id": "9dZoN-gCwxIO",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#!/usr/bin/python\n",
        "# -*- coding: utf-8 -*-\n",
        "import os\n",
        "import unittest\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.utils import check_random_state\n",
        "from sklearn.datasets import load_digits\n",
        "from sklearn.datasets import fetch_mldata\n",
        "from sklearn.decomposition import PCA\n",
        "from sklearn.metrics import confusion_matrix, classification_report, average_precision_score\n",
        "from sklearn.model_selection import cross_val_score\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.preprocessing import MinMaxScaler \n",
        "from sklearn.linear_model import LogisticRegression\n",
        "\n",
        "np.random.seed(31337)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "CgctXAqSZeje",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Decorators\n",
        "from functools import wraps\n",
        "\n",
        "\n",
        "def my_logger(orig_func):\n",
        "    import logging\n",
        "    logging.basicConfig(filename='{}.log'.format(orig_func.__name__), level=logging.INFO)\n",
        "\n",
        "    @wraps(orig_func)\n",
        "    def wrapper(*args, **kwargs):\n",
        "        logging.info(\n",
        "            'Ran with args: {}, and kwargs: {}'.format(args, kwargs))\n",
        "        return orig_func(*args, **kwargs)\n",
        "\n",
        "    return wrapper\n",
        "\n",
        "\n",
        "def my_timer(orig_func):\n",
        "    import time\n",
        "\n",
        "    @wraps(orig_func)\n",
        "    def wrapper(*args, **kwargs):\n",
        "        t1 = time.time()\n",
        "        result = orig_func(*args, **kwargs)\n",
        "        t2 = time.time() - t1\n",
        "        print('{} ran in: {} sec'.format(orig_func.__name__, t2))\n",
        "        return result\n",
        "\n",
        "    return wrapper"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "P0W8PEPEHS5f",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def download():\n",
        "    mnist = fetch_mldata('MNIST original')\n",
        "    X = mnist.data.astype('float64')\n",
        "    y = mnist.target\n",
        "    return (X, y) "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "2TwvopiOHtyg",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "class Normalize(object): \n",
        "    def normalize(self, X_train, X_test):\n",
        "        self.scaler = MinMaxScaler()\n",
        "        X_train = self.scaler.fit_transform(X_train)\n",
        "        X_test  = self.scaler.transform(X_test)\n",
        "        return (X_train, X_test) \n",
        "    \n",
        "    def inverse(self, X_train, X_val, X_test):\n",
        "        X_train = self.scaler.inverse_transform(X_train)\n",
        "        X_test  = self.scaler.inverse_transform(X_test)\n",
        "        return (X_train, X_test) "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "zYY8F6TKhXu2",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def split(X,y, splitRatio):\n",
        "    X_train = X[:splitRatio]\n",
        "    y_train = y[:splitRatio]\n",
        "    X_test = X[splitRatio:]\n",
        "    y_test = y[splitRatio:]\n",
        "    return (X_train, y_train, X_test, y_test)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "KtVQpGp9Jl7Q",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "class TheAlgorithm(object):\n",
        "  \n",
        "    @my_logger\n",
        "    @my_timer\n",
        "    def __init__(self, X_train, y_train, X_test, y_test):  \n",
        "      self.X_train, self.y_train, self.X_test, self.y_test = X_train, y_train, X_test, y_test    \n",
        "        \n",
        "    @my_logger\n",
        "    @my_timer\n",
        "    def fit(self): \n",
        "        normalizer = Normalize()\n",
        "        self.X_train, self.X_test = normalizer.normalize(self.X_train, self.X_test)   \n",
        "        train_samples = self.X_train.shape[0]\n",
        "        self.classifier = LogisticRegression(\n",
        "            C=50. / train_samples,\n",
        "            multi_class='multinomial',\n",
        "            penalty='l1',\n",
        "            solver='saga',\n",
        "            tol=0.1,\n",
        "            class_weight='balanced',\n",
        "            )\n",
        "        self.classifier.fit(self.X_train, self.y_train)\n",
        "        self.train_y_predicted = self.classifier.predict(self.X_train)\n",
        "        self.train_accuracy = np.mean(self.train_y_predicted.ravel() == self.y_train.ravel()) * 100\n",
        "        self.train_confusion_matrix = confusion_matrix(self.y_train, self.train_y_predicted)        \n",
        "        return self.train_accuracy\n",
        "    \n",
        "    @my_logger\n",
        "    @my_timer\n",
        "    def predict(self):\n",
        "        self.test_y_predicted = self.classifier.predict(self.X_test) \n",
        "        self.test_accuracy = np.mean(self.test_y_predicted.ravel() == self.y_test.ravel()) * 100 \n",
        "        self.test_confusion_matrix = confusion_matrix(self.y_test, self.test_y_predicted)        \n",
        "        self.report = classification_report(self.y_test, self.test_y_predicted)\n",
        "        print(\"Classification report for classifier:\\n %s\\n\" % (self.report))\n",
        "        return self.test_accuracy"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "16ZaBIqswFKT",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 510
        },
        "outputId": "81572ee7-0719-4c8f-fb89-63413822679a"
      },
      "cell_type": "code",
      "source": [
        "class TestInput(unittest.TestCase):\n",
        "  \n",
        "    @classmethod\n",
        "    def setUpClass(cls):\n",
        "        # print('setupClass')   \n",
        "        pass\n",
        "\n",
        "    @classmethod\n",
        "    def tearDownClass(cls): \n",
        "        # print('teardownClass')\n",
        "        pass\n",
        "\n",
        "    def setUp(self):\n",
        "        print('setUp') \n",
        "        X, y = download()\n",
        "        splitRatio = 60000\n",
        "        self.X_train, self.y_train, self.X_test, self.y_test = split(X,y,splitRatio) \n",
        "        self.train_accuracy = 72.92166666666667\n",
        "        self.train_confusion_matrix = np.matrix([[5447,   5,  40,  31,  49,  16, 198,  50,  81,   6],\n",
        "                                                 [   3,6440, 127,  54,   3,  29,  25,  36,  24,   1],\n",
        "                                                 [ 297, 420,3824, 163, 256,  19, 622, 186, 121,  50],\n",
        "                                                 [ 124, 221, 255,4566,  54, 251,  97, 129, 275, 159],\n",
        "                                                 [ 104, 128,  26,  54,4546, 342, 206, 133,  96, 207],\n",
        "                                                 [ 399, 200, 109,1081, 416,2227, 289, 363, 228, 109],\n",
        "                                                 [ 173,  89, 112,  55, 156, 229,5034,  25,  45,   0],\n",
        "                                                 [ 213, 192, 205,  39, 160,  17,  26,5058,  60, 295],\n",
        "                                                 [  67, 690, 202, 677,  73, 188, 347,  39,3437, 131],\n",
        "                                                 [ 164, 162,  63, 290, 669, 279, 122, 735, 291,3174]])\n",
        "        self.test_accuracy = 73.4\n",
        "        self.test_confusion_matrix = np.matrix([[ 923,   1,   2,   3,   3,   1,  35,   3,   9,   0],\n",
        "                                                [   0,1084,  23,  11,   0,   0,   5,   4,   8,   0],\n",
        "                                                [  63,  78, 669,  27,  38,   2,  97,  28,  24,   6],\n",
        "                                                [  20,  27,  35, 770,   8,  42,  18,  27,  45,  18],\n",
        "                                                [  15,  21,   3,   8, 750,  60,  45,  23,  18,  39],\n",
        "                                                [  56,  24,  15, 193,  73, 362,  56,  58,  38,  17],\n",
        "                                                [  35,  10,  18,  11,  28,  42, 799,   6,   8,   1],\n",
        "                                                [  23,  40,  52,   6,  21,   4,   7, 821,   8,  46],\n",
        "                                                [  14,  90,  29,  99,  10,  33,  66,   7, 598,  28],\n",
        "                                                [  21,  27,  10,  37, 133,  42,  27, 100,  48, 564]])\n",
        "\n",
        "    def tearDown(self):\n",
        "        # print('tearDown')\n",
        "        pass\n",
        "        \n",
        "    def test_fit(self):     \n",
        "        np.random.seed(31337)\n",
        "        self.ta = TheAlgorithm(self.X_train, self.y_train, self.X_test, self.y_test)\n",
        "        self.assertEqual(self.ta.fit(), self.train_accuracy) \n",
        "        self.assertEqual(self.ta.train_confusion_matrix.tolist(), self.train_confusion_matrix.tolist())  \n",
        "  \n",
        "    def test_predict(self):\n",
        "        np.random.seed(31337)\n",
        "        self.ta = TheAlgorithm(self.X_train, self.y_train, self.X_test, self.y_test)\n",
        "        self.ta.fit()\n",
        "        self.assertEqual(self.ta.predict(), self.test_accuracy)\n",
        "        self.assertEqual(self.ta.train_confusion_matrix.tolist(), self.train_confusion_matrix.tolist()) \n",
        "      \n",
        "if __name__ == '__main__':\n",
        "  \n",
        "    #run tests \n",
        "    unittest.main(argv=['first-arg-is-ignored'], exit=False)\n",
        "    "
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "setUp\n",
            "__init__ ran in: 2.384185791015625e-06 sec\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "."
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "fit ran in: 16.511127471923828 sec\n",
            "setUp\n",
            "__init__ ran in: 2.86102294921875e-06 sec\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "."
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "fit ran in: 16.124633073806763 sec\n",
            "Classification report for classifier:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "        0.0       0.79      0.94      0.86       980\n",
            "        1.0       0.77      0.96      0.85      1135\n",
            "        2.0       0.78      0.65      0.71      1032\n",
            "        3.0       0.66      0.76      0.71      1010\n",
            "        4.0       0.70      0.76      0.73       982\n",
            "        5.0       0.62      0.41      0.49       892\n",
            "        6.0       0.69      0.83      0.76       958\n",
            "        7.0       0.76      0.80      0.78      1028\n",
            "        8.0       0.74      0.61      0.67       974\n",
            "        9.0       0.78      0.56      0.65      1009\n",
            "\n",
            "avg / total       0.73      0.73      0.73     10000\n",
            "\n",
            "\n",
            "predict ran in: 0.05926704406738281 sec\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "----------------------------------------------------------------------\n",
            "Ran 2 tests in 33.171s\n",
            "\n",
            "OK\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "metadata": {
        "id": "d0Xwdkuoe8O5",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 884
        },
        "outputId": "3db63627-dd71-4a26-94d7-7ae5f5ce57d2"
      },
      "cell_type": "code",
      "source": [
        "#The solution\n",
        "if __name__ == '__main__': \n",
        "  \n",
        "  X,y = download()\n",
        "  print ('MNIST:', X.shape, y.shape)\n",
        "  \n",
        "  splitRatio = 60000\n",
        "  X_train, y_train, X_test, y_test = split(X,y,splitRatio) \n",
        "\n",
        "  np.random.seed(31337)\n",
        "  ta = TheAlgorithm(X_train, y_train, X_test, y_test)\n",
        "  train_accuracy = ta.fit()\n",
        "  print()\n",
        "  print('Train Accuracy:', train_accuracy,'\\n') \n",
        "  print(\"Train confusion matrix:\\n%s\\n\" % ta.train_confusion_matrix)\n",
        "  \n",
        "  test_accuracy = ta.predict()\n",
        "  print()\n",
        "  print('Test Accuracy:', test_accuracy,'\\n') \n",
        "  print(\"Test confusion matrix:\\n%s\\n\" % ta.test_confusion_matrix)"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "MNIST: (70000, 784) (70000,)\n",
            "__init__ ran in: 3.337860107421875e-06 sec\n",
            "fit ran in: 15.876034498214722 sec\n",
            "\n",
            "Train Accuracy: 72.92166666666667 \n",
            "\n",
            "Train confusion matrix:\n",
            "[[5447    5   40   31   49   16  198   50   81    6]\n",
            " [   3 6440  127   54    3   29   25   36   24    1]\n",
            " [ 297  420 3824  163  256   19  622  186  121   50]\n",
            " [ 124  221  255 4566   54  251   97  129  275  159]\n",
            " [ 104  128   26   54 4546  342  206  133   96  207]\n",
            " [ 399  200  109 1081  416 2227  289  363  228  109]\n",
            " [ 173   89  112   55  156  229 5034   25   45    0]\n",
            " [ 213  192  205   39  160   17   26 5058   60  295]\n",
            " [  67  690  202  677   73  188  347   39 3437  131]\n",
            " [ 164  162   63  290  669  279  122  735  291 3174]]\n",
            "\n",
            "Classification report for classifier:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "        0.0       0.79      0.94      0.86       980\n",
            "        1.0       0.77      0.96      0.85      1135\n",
            "        2.0       0.78      0.65      0.71      1032\n",
            "        3.0       0.66      0.76      0.71      1010\n",
            "        4.0       0.70      0.76      0.73       982\n",
            "        5.0       0.62      0.41      0.49       892\n",
            "        6.0       0.69      0.83      0.76       958\n",
            "        7.0       0.76      0.80      0.78      1028\n",
            "        8.0       0.74      0.61      0.67       974\n",
            "        9.0       0.78      0.56      0.65      1009\n",
            "\n",
            "avg / total       0.73      0.73      0.73     10000\n",
            "\n",
            "\n",
            "predict ran in: 0.06237649917602539 sec\n",
            "\n",
            "Test Accuracy: 73.4 \n",
            "\n",
            "Test confusion matrix:\n",
            "[[ 923    1    2    3    3    1   35    3    9    0]\n",
            " [   0 1084   23   11    0    0    5    4    8    0]\n",
            " [  63   78  669   27   38    2   97   28   24    6]\n",
            " [  20   27   35  770    8   42   18   27   45   18]\n",
            " [  15   21    3    8  750   60   45   23   18   39]\n",
            " [  56   24   15  193   73  362   56   58   38   17]\n",
            " [  35   10   18   11   28   42  799    6    8    1]\n",
            " [  23   40   52    6   21    4    7  821    8   46]\n",
            " [  14   90   29   99   10   33   66    7  598   28]\n",
            " [  21   27   10   37  133   42   27  100   48  564]]\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}